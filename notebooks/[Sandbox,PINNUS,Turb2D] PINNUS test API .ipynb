{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6328122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046de65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.trainer import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from turboflow.dataloaders import TurboFlowDataModule\n",
    "from turboflow.evaluation import compute_all_metrics\n",
    "\n",
    "from turboflow.utils import phy_utils as phy\n",
    "from turboflow.utils import torch_utils as tch\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc8bb501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ed20650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data_dir = Path('/','home','dicarlo_d','Documents','Datasets','Turb2D.hdf5')\n",
    "dm = TurboFlowDataModule(dataset='Turb2D', \n",
    "                         data_dir=data_dir,\n",
    "                         batch_size=100000,\n",
    "                         time_idx=666,\n",
    "                         train_downsampling=32,\n",
    "                         val_downsampling=32,\n",
    "                         test_downsampling=1,\n",
    "                         num_workers=1)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4e75c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Resolution data: 64 8\n",
      "High Resolution data: 65536 256\n"
     ]
    }
   ],
   "source": [
    "X_lr, y_lr = dm.val_dataset[:]\n",
    "img_shape_lr = dm.val_dataset.img_shape[:2]\n",
    "shape_lr = dm.val_dataset.img_shape\n",
    "L = shape_lr[0]\n",
    "N_lr = X_lr.shape[0]\n",
    "print('Low Resolution data:', N_lr, L)\n",
    "\n",
    "X_hr, y_hr = dm.test_dataset[:]\n",
    "img_shape_hr = dm.test_dataset.img_shape[:2]\n",
    "shape_hr = dm.test_dataset.img_shape\n",
    "H = shape_hr[0]\n",
    "N_hr = X_hr.shape[0]\n",
    "print('High Resolution data:', N_hr, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdef8b72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from turboflow.models.phyrff import plDivFreeRFFNet\n",
    "\n",
    "# choose the hyperparams\n",
    "hparams = {\n",
    "    'name':'RFFNet',\n",
    "    'mlp_layers_num': 10,\n",
    "    'mlp_layers_dim': 256, \n",
    "    'mlp_last_actfn': 'tanh',\n",
    "    'do_rff': True, \n",
    "    'rff_num': 512, \n",
    "    'rff_scale': 10,\n",
    "    'do_divfree': True,\n",
    "    'lam_sdiv': 0,     # spatial grad(u,v) = torch.autograd(u,v)\n",
    "    'lam_sfn':  0,     # offgrid L2 reg. on Sfun\n",
    "    'lam_spec': 0,     # L2 diff on the spectrum\n",
    "    'lam_grads':0,     # offrgid L2 reg. on grad and autograd\n",
    "    'lam_curl' :0,     # smooth grad of vorticity\n",
    "    'lam_pde' : 0,\n",
    "    'lam_weight': 1e-3,  # L2 reg on the NN's weights\n",
    "    'sfn_min_x': 1./256., # maximal resolution\n",
    "    'sfn_num_centers': 32,\n",
    "    'sfn_num_increments':8,\n",
    "    'sfn_patch_dim': 16 # (P/2)\n",
    "}\n",
    "\n",
    "model = plDivFreeRFFNet(**vars(Namespace(**hparams)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de4bba98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dicarlo_d/Documents/Code/TurboSuperResultion/venv/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:446: UserWarning: Checkpoint directory .torch_checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(monitor='val/loss/tot')\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val/loss/tot\",\n",
    "    dirpath=\".torch_checkpoints\",\n",
    "    filename=\"Turb2D-%s-{epoch:02d}-{val_loss:.2f}\" % (hparams['name']),\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(gpus=1,\n",
    "                  max_epochs=3000, \n",
    "                  log_every_n_steps=20,\n",
    "                  check_val_every_n_epoch=20, \n",
    "                  callbacks=[early_stop_callback,\n",
    "                             checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfea36c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dicarlo_d/Documents/Code/TurboSuperResultion/venv/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2022-01-24 12:19:12.619500: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "\n",
      "  | Name    | Type            | Params\n",
      "--------------------------------------------\n",
      "0 | rff     | Fourier         | 1.0 K \n",
      "1 | mlp     | MLP             | 854 K \n",
      "2 | div     | DivFree         | 0     \n",
      "3 | sp_grad | SpatialGradient | 0     \n",
      "4 | sp_lapl | Laplacian       | 0     \n",
      "--------------------------------------------\n",
      "854 K     Trainable params\n",
      "1.0 K     Non-trainable params\n",
      "855 K     Total params\n",
      "3.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dicarlo_d/Documents/Code/TurboSuperResultion/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 42\n",
      "/home/dicarlo_d/Documents/Code/TurboSuperResultion/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/dicarlo_d/Documents/Code/TurboSuperResultion/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:326: UserWarning: The number of training samples (1) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08152a18bd26401da991c5d9af185a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dicarlo_d/Documents/Code/TurboSuperResultion/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1046: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad776cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_ln = torch.arange(0, 1, 1/64)\n",
    "print(patch_ln)\n",
    "R = patch_ln.shape[0]\n",
    "# make it square meshgrid\n",
    "patch_sq = torch.stack(torch.meshgrid(patch_ln, patch_ln), dim=-1)\n",
    "patch_sq = patch_sq.view(-1,2)\n",
    "\n",
    "X = X_lr\n",
    "R = int(X.shape[0]**0.5)\n",
    "y = model(X)[0]\n",
    "print(y.shape)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(y.reshape(R,R,2).detach().cpu()[:,:,0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(y.reshape(R,R,2).detach().cpu()[:,:,1])\n",
    "plt.show()\n",
    "\n",
    "X = patch_sq\n",
    "R = int(X.shape[0]**0.5)\n",
    "y = model(X)[0]\n",
    "print(y.shape)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(y.reshape (R,R,2).detach().cpu()[:,:,0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(y.reshape(R,R,2).detach().cpu()[:,:,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74997ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = X_hr\n",
    "R = int(X.shape[0]**0.5)\n",
    "\n",
    "from kornia.filters import SpatialGradient\n",
    "sp_grad = SpatialGradient(mode='sobel',normalized=True)\n",
    "\n",
    "X.requires_grad_(True)\n",
    "y = model(X)[0]\n",
    "u, v = torch.split(y,1,-1)\n",
    "du_xy = torch.autograd.grad(u, X, torch.ones_like(u), create_graph=True)[0] # Bx2 \n",
    "dv_xy = torch.autograd.grad(v, X, torch.ones_like(v), create_graph=True)[0] # Bx2\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(141)\n",
    "plt.imshow(du_xy.reshape (R,R,2).detach().cpu()[:,:,0] / (R*2))\n",
    "plt.subplot(142)\n",
    "plt.imshow(du_xy.reshape(R,R,2).detach().cpu()[:,:,1] / (R*2))\n",
    "plt.subplot(143)\n",
    "plt.imshow(du_xy.reshape (R,R,2).detach().cpu()[:,:,0] / (R*2))\n",
    "plt.subplot(144)\n",
    "plt.imshow(du_xy.reshape(R,R,2).detach().cpu()[:,:,1] / (R*2))\n",
    "plt.show()\n",
    "\n",
    "y_img_hat = y_hr.view(R,R,2)[None,...].permute(0,3,1,2)\n",
    "grads = sp_grad(y_img_hat) # Nx2x2xHxW\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(141)\n",
    "plt.imshow(grads[0,0,1,...].detach().numpy())\n",
    "plt.subplot(142)\n",
    "plt.imshow(grads[0,0,0,...].detach().numpy())\n",
    "plt.subplot(143)\n",
    "plt.imshow(grads[0,1,1,...].detach().numpy())\n",
    "plt.subplot(144)\n",
    "plt.imshow(grads[0,1,0,...].detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0eff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7a3daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grads = '/home/dicarlo_d/Documents/Code/TurboSuperResultion/notebooks/.torch_checkpoints/Turb2D-RFFNet-epoch=1019-val_loss=0.01.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da145ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lr, y_lr = dm.val_dataset[:]\n",
    "img_shape_lr = dm.val_dataset.img_shape[:2]\n",
    "shape_lr = dm.val_dataset.img_shape\n",
    "\n",
    "X_hr, y_hr = dm.test_dataset[:]\n",
    "img_shape_hr = dm.test_dataset.img_shape[:2]\n",
    "shape_hr = dm.test_dataset.img_shape\n",
    "\n",
    "print(X_lr.shape, y_lr.shape)\n",
    "print(X_hr.shape, y_hr.shape)\n",
    "\n",
    "y_hat_lr, P_hat_lr = model(X_lr)\n",
    "y_hat_hr, P_hat_hr = model(X_hr)\n",
    "\n",
    "print(y_hat_lr.shape)\n",
    "print(y_hat_hr.shape)\n",
    "\n",
    "err_lr = torch.abs(y_hat_lr - y_lr)**2\n",
    "err_hr = torch.abs(y_hat_hr - y_hr)**2\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "plt.title('Pred LR')\n",
    "plt.imshow(y_hat_lr[:,0].reshape(*img_shape_lr).detach())\n",
    "plt.subplot(132)\n",
    "plt.title('GT LR')\n",
    "plt.imshow(y_lr[:,0].reshape(*img_shape_lr).detach())\n",
    "plt.subplot(133)\n",
    "plt.title('Error LR')\n",
    "plt.imshow(err_lr[:,0].reshape(*img_shape_lr).detach())\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "plt.title('Pred HR')\n",
    "plt.imshow(y_hat_hr[:,0].reshape(*img_shape_hr).detach())\n",
    "plt.subplot(132)\n",
    "plt.title('GT HR')\n",
    "plt.imshow(y_hr[:,0].reshape(*img_shape_hr).detach())\n",
    "plt.subplot(133)\n",
    "plt.title('Error HR')\n",
    "plt.imshow(err_hr[:,0].reshape(*img_shape_hr)[5:-5,5:-5].detach())\n",
    "plt.show()\n",
    "\n",
    "if P_hat_hr is not None:\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(121)\n",
    "    plt.title('Pred LR')\n",
    "    plt.imshow(P_hat_lr[:,0].reshape(*img_shape_lr).detach())\n",
    "    plt.subplot(122)\n",
    "    plt.title('GT LR')\n",
    "    plt.imshow(P_hat_hr[:,0].reshape(*img_shape_hr).detach())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531d9baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kornia.filters import SpatialGradient\n",
    "sp_grad = SpatialGradient(mode='diff',normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a843d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 64\n",
    "x = torch.linspace(0, 1, res, device=model.device)\n",
    "xx, xy = torch.meshgrid([x, x])\n",
    "x = torch.cat([xx.flatten()[:,None], xy.flatten()[:,None]], dim=-1)\n",
    "x.requires_grad_(True)\n",
    "y_hat_off, _ = model.forward(x)\n",
    "\n",
    "plt.imshow(y_hat_off[:,0].reshape(res,res).detach())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the spatial gradient of the groundtruth\n",
    "y_img_hat = y_lr.view(1,L,L,2).permute(0,3,1,2)\n",
    "grads = sp_grad(y_img_hat)\n",
    "img_u_x = grads[0,0,1,...] # we take this inverted as it was we are doing ij indexing\n",
    "img_u_y = grads[0,0,0,...] # we take this inverted as it was we are doing ij indexing\n",
    "img_v_x = grads[0,1,1,...] # we take this inverted as it was we are doing ij indexing\n",
    "img_v_y = grads[0,1,0,...] # we take this inverted as it was we are doing ij indexing\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.suptitle('Spatial gradient LR')\n",
    "plt.subplot(141)\n",
    "plt.imshow(img_u_x.detach())\n",
    "plt.subplot(142)\n",
    "plt.imshow(img_u_y.detach())\n",
    "plt.subplot(143)\n",
    "plt.imshow(img_v_x.detach())\n",
    "plt.subplot(144)\n",
    "plt.imshow(img_v_y.detach())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# compute the spatial gradient of the prediction\n",
    "y_img_hat = y_hat_off.view(1,res,res,2).permute(0,3,1,2)\n",
    "grads = sp_grad(y_img_hat)\n",
    "img_u_x = grads[0,0,1,...] # we take this inverted as it was we are doing ij indexing\n",
    "img_u_y = grads[0,0,0,...] # we take this inverted as it was we are doing ij indexing\n",
    "img_v_x = grads[0,1,1,...] # we take this inverted as it was we are doing ij indexing\n",
    "img_v_y = grads[0,1,0,...] # we take this inverted as it was we are doing ij indexing\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.suptitle('Spatial gradient HR')\n",
    "plt.subplot(141)\n",
    "plt.imshow(img_u_x.detach())\n",
    "plt.subplot(142)\n",
    "plt.imshow(img_u_y.detach())\n",
    "plt.subplot(143)\n",
    "plt.imshow(img_v_x.detach())\n",
    "plt.subplot(144)\n",
    "plt.imshow(img_v_y.detach())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# compute the gradient of the prediction with autograd\n",
    "u, v = torch.split(y_hat_off,1,-1)\n",
    "du_xy = torch.autograd.grad(u, x, torch.ones_like(u), create_graph=True)[0]\n",
    "dv_xy = torch.autograd.grad(v, x, torch.ones_like(v), create_graph=True)[0]\n",
    "\n",
    "du_x = du_xy[:,0].reshape(res,res) / res\n",
    "du_y = du_xy[:,1].reshape(res,res) / res\n",
    "dv_x = dv_xy[:,0].reshape(res,res) / res\n",
    "dv_y = dv_xy[:,1].reshape(res,res) / res\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.suptitle('Autograd gradient HR')\n",
    "plt.subplot(141)\n",
    "plt.imshow(du_x.detach())\n",
    "plt.subplot(142)\n",
    "plt.imshow(du_y.detach())\n",
    "plt.subplot(143)\n",
    "plt.imshow(dv_x.detach())\n",
    "plt.subplot(144)\n",
    "plt.imshow(dv_y.detach())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "gdiff_u_x = torch.abs(img_u_x - du_x)**1\n",
    "gdiff_u_y = torch.abs(img_u_y - du_y)**1\n",
    "gdiff_v_x = torch.abs(img_v_x - dv_x)**1\n",
    "gdiff_v_y = torch.abs(img_v_y - dv_y)**1\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(141)\n",
    "plt.imshow(gdiff_u_x.detach().cpu())\n",
    "plt.subplot(142)\n",
    "plt.imshow(gdiff_u_y.detach().cpu())\n",
    "plt.subplot(143)\n",
    "plt.imshow(gdiff_v_x.detach().cpu())\n",
    "plt.subplot(144)\n",
    "plt.imshow(gdiff_v_y.detach().cpu())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fc9bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = dv_x - du_y\n",
    "plt.imshow(w.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8216224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_lr[:,0].detach()\n",
    "y = X_lr[:,1].detach()\n",
    "u = y_hat_lr[:,0].detach()\n",
    "v = y_hat_lr[:,1].detach()\n",
    "\n",
    "s = 1\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "plt.quiver(x.reshape(*img_shape_lr)[::s,::s], \n",
    "           y.reshape(*img_shape_lr)[::s,::s],\n",
    "           u.reshape(*img_shape_lr)[::s,::s],\n",
    "           v.reshape(*img_shape_lr)[::s,::s], scale=10)\n",
    "plt.subplot(122)\n",
    "plt.quiver(        x.reshape(*img_shape_lr)[::s,::s], \n",
    "                   y.reshape(*img_shape_lr)[::s,::s],\n",
    "           y_lr[:,0].reshape(*img_shape_lr)[::s,::s],\n",
    "           y_lr[:,1].reshape(*img_shape_lr)[::s,::s], scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02722f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_lr[:,0].detach()\n",
    "y = X_lr[:,1].detach()\n",
    "u_diff = y_hat_lr[:,0].detach() - y_lr[:,0].detach()\n",
    "v_diff = y_hat_lr[:,1].detach() - y_lr[:,1].detach()\n",
    "\n",
    "s = 1\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.quiver(x.reshape(*img_shape_lr)[::s,::s], \n",
    "           y.reshape(*img_shape_lr)[::s,::s],\n",
    "           u_diff.reshape(*img_shape_lr)[::s,::s],\n",
    "           v_diff.reshape(*img_shape_lr)[::s,::s], scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a562249",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 1\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.streamplot(        \n",
    "           x.reshape(*img_shape_lr)[::s,::s].T.numpy(), \n",
    "           y.reshape(*img_shape_lr)[::s,::s].T.numpy(),\n",
    "           y_lr[:,0].reshape(*img_shape_lr)[::s,::s].T.numpy(),\n",
    "           y_lr[:,1].reshape(*img_shape_lr)[::s,::s].T.numpy(), density=2)\n",
    "plt.streamplot(x.reshape(*img_shape_lr)[::s,::s].T.numpy(), \n",
    "           y.reshape(*img_shape_lr)[::s,::s].T.numpy(),\n",
    "           u.reshape(*img_shape_lr)[::s,::s].T.numpy(),\n",
    "           v.reshape(*img_shape_lr)[::s,::s].T.numpy(), density=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8116d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_hr[:,0].detach()\n",
    "y = X_hr[:,1].detach()\n",
    "u = y_hat_hr[:,0].detach()\n",
    "v = y_hat_hr[:,1].detach()\n",
    "\n",
    "s = 4\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "plt.quiver(x.reshape(*img_shape_hr)[::s,::s], \n",
    "           y.reshape(*img_shape_hr)[::s,::s],\n",
    "           u.reshape(*img_shape_hr)[::s,::s],\n",
    "           v.reshape(*img_shape_hr)[::s,::s], scale=10)\n",
    "plt.subplot(122)\n",
    "plt.quiver(        x.reshape(*img_shape_hr)[::s,::s], \n",
    "                   y.reshape(*img_shape_hr)[::s,::s],\n",
    "           y_hr[:,0].reshape(*img_shape_hr)[::s,::s],\n",
    "           y_hr[:,1].reshape(*img_shape_hr)[::s,::s], scale=10)\n",
    "\n",
    "\n",
    "x = X_hr[:,0].detach()\n",
    "y = X_hr[:,1].detach()\n",
    "u_diff = y_hat_hr[:,0].detach() - y_hr[:,0].detach()\n",
    "v_diff = y_hat_hr[:,1].detach() - y_hr[:,1].detach()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.quiver(x.reshape(*img_shape_hr)[::s,::s], \n",
    "           y.reshape(*img_shape_hr)[::s,::s],\n",
    "           u_diff.reshape(*img_shape_hr)[::s,::s],\n",
    "           v_diff.reshape(*img_shape_hr)[::s,::s], scale=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71860da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 1\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.streamplot(\n",
    "           x.reshape(*img_shape_hr)[::s,::s].T.numpy(), \n",
    "           y.reshape(*img_shape_hr)[::s,::s].T.numpy(),\n",
    "           u.reshape(*img_shape_hr)[::s,::s].T.numpy(),\n",
    "           v.reshape(*img_shape_hr)[::s,::s].T.numpy(),density=3)\n",
    "plt.streamplot(        \n",
    "           x.reshape(*img_shape_hr)[::s,::s].T.numpy(), \n",
    "           y.reshape(*img_shape_hr)[::s,::s].T.numpy(),\n",
    "           y_hr[:,0].reshape(*img_shape_hr)[::s,::s].T.numpy(),\n",
    "           y_hr[:,1].reshape(*img_shape_hr)[::s,::s].T.numpy(),density=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29783702",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_hr[:,0].detach()\n",
    "y = X_hr[:,1].detach()\n",
    "u = y_hat_hr[:,0].detach()\n",
    "v = y_hat_hr[:,1].detach()\n",
    "\n",
    "d = 1\n",
    "l = 64\n",
    "s = 10\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "plt.quiver(x.reshape(*img_shape_hr)[:l:d,:l:d], \n",
    "           y.reshape(*img_shape_hr)[:l:d,:l:d],\n",
    "           u.reshape(*img_shape_hr)[:l:d,:l:d],\n",
    "           v.reshape(*img_shape_hr)[:l:d,:l:d], scale=s)\n",
    "plt.subplot(122)\n",
    "plt.quiver(        x.reshape(*img_shape_hr)[:l:d,:l:d], \n",
    "                   y.reshape(*img_shape_hr)[:l:d,:l:d],\n",
    "           y_hr[:,0].reshape(*img_shape_hr)[:l:d,:l:d],\n",
    "           y_hr[:,1].reshape(*img_shape_hr)[:l:d,:l:d], scale=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5335763",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_hr[:,0].detach()\n",
    "y = X_hr[:,1].detach()\n",
    "u = y_hat_hr[:,0].detach()\n",
    "v = y_hat_hr[:,1].detach()\n",
    "\n",
    "d = 1\n",
    "l = 64\n",
    "s = 10\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(u.reshape(*img_shape_hr)[:l:d,:l:d])\n",
    "plt.subplot(122)\n",
    "plt.imshow(y_hr[:,0].reshape(*img_shape_hr)[:l:d,:l:d])\n",
    "plt.show()\n",
    "plt.imshow((y_hr[:,0]-u).reshape(*img_shape_hr)[:l:d,:l:d])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addd0d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_all_metrics(y_hat_lr, y_lr))\n",
    "print(compute_all_metrics(y_hat_hr, y_hr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6f60e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute spectrum\n",
    "spec_ns = phy.energy_spectrum(torch.randn(*shape_hr).permute(2,0,1))[0]\n",
    "spec_lr = phy.energy_spectrum(y_lr.view(*shape_lr).permute(2,0,1))[0]\n",
    "spec_hr = phy.energy_spectrum(y_hr.view(*shape_hr).permute(2,0,1))[0]\n",
    "\n",
    "spec_lr_pred = phy.energy_spectrum(y_hat_lr.view(*shape_lr).permute(2,0,1))[0]\n",
    "spec_hr_pred = phy.energy_spectrum(y_hat_hr.view(*shape_hr).permute(2,0,1))[0]\n",
    "\n",
    "# plt.loglog(spec_ns)\n",
    "plt.loglog(spec_lr)\n",
    "plt.loglog(spec_hr)\n",
    "plt.loglog(spec_lr_pred.detach())\n",
    "plt.loglog(spec_hr_pred.detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f705448",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = (spec_hr - spec_hr_pred)\n",
    "plt.plot(err.detach())\n",
    "plt.plot(spec_hr.detach())\n",
    "plt.plot(spec_hr_pred.detach())\n",
    "print(err.sum())\n",
    "print()\n",
    "# spec error\n",
    "# spec_log_error_lr = torch.norm(torch.log(spec_lr_pred+1e-20) - torch.log(spec_lr+1e-20))**2\n",
    "# spec_log_error_hr = torch.norm(torch.log(spec_hr_pred+1e-20) - torch.log(spec_hr+1e-20))**2\n",
    "\n",
    "# print(spec_error_lr.item())\n",
    "# print(spec_error_hr.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b426d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# angular error\n",
    "def ang_error(x, x_ref, avg=True):\n",
    "    assert x.shape == x_ref.shape\n",
    "    assert x.shape[1] == 2\n",
    "    N = x.shape[0]\n",
    "    \n",
    "    w1 = torch.cat([x, torch.ones(x.shape[0], 1)], dim=1)\n",
    "    w2 = torch.cat([x_ref, torch.ones(x_ref.shape[0], 1)], dim=1)\n",
    "    \n",
    "    err = torch.sum(w1 * w2, dim=1) / (torch.norm(w1, dim=1) * torch.norm(w2, dim=1))\n",
    "    assert err.sum() < N\n",
    "    err = torch.rad2deg(torch.acos(err))\n",
    "    if avg:\n",
    "        return err.mean()\n",
    "    return err\n",
    "    \n",
    "\n",
    "ang_err_lr = ang_error(y_lr, y_hat_lr, avg=True)\n",
    "ang_err_hr = ang_error(y_hr, y_hat_hr, avg=True)\n",
    "\n",
    "print(torch.max(ang_error(y_lr, y_hat_lr, avg=False)))\n",
    "print(torch.max(ang_error(y_hr, y_hat_hr, avg=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c34579",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = plDivFreeRFFNet.load_from_checkpoint(checkpoint_callback.best_model_path)\n",
    "trainer.test(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_lr_err = phy.energy_spectrum(((y_hat_lr-y_lr)**2).view(*img_shape_lr).permute(2,0,1))[0]\n",
    "spec_hr_err = phy.energy_spectrum(((y_hat_hr-y_hr)**2).view(*img_shape_hr).permute(2,0,1))[0]\n",
    "\n",
    "plt.loglog(spec_lr_err.detach())\n",
    "plt.loglog(spec_hr_err.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abfbd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat, Py_hat = model(X_lr)\n",
    "u, v = torch.split(y_hat,1,-1)\n",
    "du_xy = torch.autograd.grad(u, X_lr, torch.ones_like(u), create_graph=True)[0]       \n",
    "dv_xy = torch.autograd.grad(v, X_lr, torch.ones_like(v), create_graph=True)[0]\n",
    "# div_autograd = du_xy[...,0] + dv_xy[...,1]\n",
    "div_autograd = dv_xy[...,1]\n",
    "div_autograd = div_autograd.view(*img_shape_lr[:2])\n",
    "\n",
    "plt.imshow(div_autograd.detach())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "du_x = tch._my_field_grad(y_hat.view(*img_shape_lr)[:,:,0], 1)\n",
    "du_y = tch._my_field_grad(y_hat.view(*img_shape_lr)[:,:,1], 0)\n",
    "div_numerical = du_y\n",
    "    \n",
    "plt.imshow(div_numerical.detach())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow((div_numerical - div_autograd).detach())\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67538680",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat, Py_hat = model(X_hr)\n",
    "u, v = torch.split(y_hat,1,-1)\n",
    "du_xy = torch.autograd.grad(u, X_hr, torch.ones_like(u), create_graph=True)[0]       \n",
    "dv_xy = torch.autograd.grad(v, X_hr, torch.ones_like(v), create_graph=True)[0]\n",
    "# div_autograd = du_xy[...,0] + dv_xy[...,1]\n",
    "div_autograd = dv_xy[...,1]\n",
    "div_autograd = div_autograd.view(*img_shape_hr[:2])\n",
    "\n",
    "plt.imshow(div_autograd[2:-2,2:-2].detach())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "du_x = tch._my_field_grad(y_hat.view(*img_shape_hr)[:,:,0], 1)\n",
    "du_y = tch._my_field_grad(y_hat.view(*img_shape_hr)[:,:,1], 0)\n",
    "div_numerical = du_y\n",
    "    \n",
    "plt.imshow(div_numerical[2:-2,2:-2].detach())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow((div_numerical[2:-2,2:-2] - div_autograd[2:-2,2:-2]).detach())\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f883a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
