{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033f3d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3828bbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1673, -1.5006],\n",
      "        [-1.6214,  2.3846],\n",
      "        [-4.9490,  4.8836],\n",
      "        [ 1.7014,  0.1088],\n",
      "        [ 0.8186, -2.7692],\n",
      "        [-3.2884,  6.9571],\n",
      "        [ 4.8860, -0.8622],\n",
      "        [ 1.7091, -0.5310],\n",
      "        [-0.5050, -0.4975],\n",
      "        [-0.6334,  4.7950]], grad_fn=<MulBackward0>)\n",
      "tensor([[-7.1526e-07,  5.9605e-07],\n",
      "        [-8.3447e-07,  9.5367e-07],\n",
      "        [-4.7684e-07, -4.7684e-07],\n",
      "        [ 2.0266e-06, -7.4506e-09],\n",
      "        [ 1.3709e-06,  2.3842e-07],\n",
      "        [-2.3842e-07,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.4305e-06],\n",
      "        [-1.3113e-06, -1.1325e-06],\n",
      "        [-1.1921e-07, -6.5565e-07],\n",
      "        [ 1.1921e-06,  1.4305e-06]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Fourier(nn.Module):\n",
    "    \n",
    "    def __init__(self, nfeat, scale):\n",
    "        super(Fourier, self).__init__()\n",
    "        self.b = nn.Parameter(torch.randn(2, nfeat)*scale, requires_grad=False)\n",
    "        self.pi = 3.14159265359\n",
    "\n",
    "    def forward(self, x):\n",
    "        size = x.shape[0]\n",
    "        x = (2*self.pi*x) @ self.b.to(x.device)\n",
    "        assert x.shape[0] == size\n",
    "        assert x.shape[1] == self.b.shape[1]\n",
    "        return torch.cat([torch.sin(x), torch.cos(x)], -1)\n",
    "    \n",
    "\n",
    "def LinearTanh(n_in, n_out):\n",
    "    # do not work with ModuleList here either.\n",
    "    block = nn.Sequential(\n",
    "      nn.Linear(n_in, n_out),\n",
    "      nn.Tanh()\n",
    "    )\n",
    "    return block\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_layers, nfeat, scale):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        num_layers = len(dim_layers)\n",
    "        \n",
    "        blocks = []\n",
    "        for l in range(num_layers-1):\n",
    "            blocks.append(LinearTanh(dim_layers[l], dim_layers[l+1]))\n",
    "\n",
    "        self.mlp = nn.Sequential(*blocks)\n",
    "        \n",
    "        self.sigma = lambda x : torch.tanh(x)\n",
    "        self.dsigma = lambda x : 1-torch.tanh(x)**2\n",
    "        self.ddsigma = lambda x : -2*torch.tanh(x)*(1-torch.tanh(x)**2)\n",
    "        \n",
    "        self.rff = Fourier(nfeat, scale)\n",
    "        self.sincos = lambda x : torch.cat([torch.sin(x), torch.cos(x)], -1)\n",
    "        self.dsincos = lambda x : torch.cat([torch.cos(x), -torch.sin(x)], -1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.rff(x)\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def get_wb(self, depth):\n",
    "        return self.mlp[depth][0].weight, self.mlp[depth][0].bias\n",
    "    \n",
    "    def compute_ux(self, x):\n",
    "        # RFF\n",
    "        Wr = self.rff.b\n",
    "        Wr2 = torch.cat([Wr, Wr], axis=1).T\n",
    "        \n",
    "        dr = 2*self.rff.pi*self.dsincos(2*self.rff.pi*x @ Wr) # B x nfeat\n",
    "        ar = self.sincos(2*self.rff.pi*x @ Wr) # B x nfeat\n",
    "#         z = dr @ Wr\n",
    "\n",
    "        # MLP\n",
    "#         W1, b1 = self.get_wb(0)\n",
    "#         d1 = self.dsigma(x @ W1.T + b1)\n",
    "#         a1 = self.sigma(x @ W1.T + b1)\n",
    "        \n",
    "        W1, b1 = self.get_wb(0)\n",
    "        d1 = self.dsigma(ar @ W1.T + b1)\n",
    "        a1 = self.sigma(ar @ W1.T + b1)\n",
    "        \n",
    "        z = ((d1 @ W1) * dr) @ Wr2\n",
    "#         z = d1 @ W1\n",
    "        \n",
    "        W2, b2 = self.get_wb(1)\n",
    "        d2 = self.dsigma(a1 @ W2.T + b2)\n",
    "        a2 = self.sigma(a1 @ W2.T + b2)\n",
    "#         z = (d2 @ W2) * d1) @ W1\n",
    "        z = ((((d2 @ W2) * d1) @ W1) * dr) @ Wr2\n",
    "        \n",
    "        W3, b3 = self.get_wb(2)\n",
    "        d3 = self.dsigma(a2 @ W3.T + b3)\n",
    "        a3 = self.sigma(a2 @ W3.T + b3)\n",
    "#         z = (d3 @ W3 * d2) @ W2 * d1) @ W1\n",
    "        z = (((((d3 @ W3 * d2) @ W2) * d1) @ W1) * dr) @ Wr2\n",
    "        \n",
    "        W4, b4 = self.get_wb(3)\n",
    "        d4 = self.dsigma(a3 @ W4.T + b4)\n",
    "        a4 = self.sigma(a3 @ W4.T + b4)        \n",
    "#         z = ((((d4 @ W4 * d3) @ W3 * d2) @ W2 * d1) @ W1\n",
    "        z = ((((((d4 @ W4 * d3) @ W3 * d2) @ W2) * d1) @ W1) * dr) @ Wr2\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def compute_uxx(self, x):\n",
    "        W1, b1 = self.get_wb(0)\n",
    "        d1 = self.ddsigma(x@W1 + b1)\n",
    "        z = d1 @ W1**2\n",
    "        return z\n",
    "    \n",
    "dim_in = 2\n",
    "nfeat = 256\n",
    "scale = 10\n",
    "\n",
    "mlp_layers = [2*nfeat] + 3*[256] + [1]\n",
    "\n",
    "mlp = MLP(mlp_layers, nfeat, scale)\n",
    "\n",
    "x = torch.randn(10,dim_in)\n",
    "x.requires_grad_(True)\n",
    "y = mlp(x)\n",
    "\n",
    "ux1_auto = torch.autograd.grad(y, x, torch.ones_like(y), retain_graph=True, create_graph=True)[0]\n",
    "print(ux1_auto)\n",
    "ux1_analy = mlp.compute_ux(x)\n",
    "print(ux1_auto - ux1_analy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aadfff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a84852e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
