{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6328122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8824f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "046de65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from pytorch_lightning.trainer import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from turboflow.dataloaders import TurboFlowDataModule\n",
    "from turboflow.evaluation import compute_all_metrics\n",
    "\n",
    "from turboflow.utils import phy_utils as phy\n",
    "from turboflow.utils import torch_utils as tch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8bb501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ed20650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data_dir = Path('/','home','dicarlo_d','Documents','Datasets','Turb2D.hdf5')\n",
    "dm = TurboFlowDataModule(dataset='Turb2D', \n",
    "                         data_dir=data_dir,\n",
    "                         batch_size=100000,\n",
    "                         time_idx=33,\n",
    "                         train_downsampling=16,\n",
    "                         val_downsampling=16,\n",
    "                         test_downsampling=1,\n",
    "                         num_workers=1)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ab9c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the hyperparams\n",
    "hparams = {\n",
    "    'name':'RFFNet',\n",
    "    'mlp_layers_num': 1,\n",
    "    'mlp_layers_dim': 256, \n",
    "    'mlp_last_actfn': 'tanh',\n",
    "    'do_rff': True, \n",
    "    'rff_num': 128, \n",
    "    'rff_scale': 10,\n",
    "    'do_divfree': True,\n",
    "    'lam_pde': 0,     # soft constr. grad(u,v)=0\n",
    "    'lam_sdiv': 0,     # spatial grad(u,v) = torch.autograd(u,v)\n",
    "    'lam_sfn': 1e-5,     # offgrid L2 reg. on Sfun\n",
    "    'lam_spec': 0,    # L2 diff on the spectrum\n",
    "    'lam_grads':1e-3,    # offrgid L2 reg. on grad and autograd\n",
    "    'lam_weight': 0,  # L2 reg on the NN's weights\n",
    "    'sfn_min_x': 0.00784314,\n",
    "    'sfn_num_centers': 50,\n",
    "    'sfn_num_increments':3,\n",
    "    'sfn_patch_dim': 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdef8b72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dicarlo_d/Documents/Code/TurboSuperResultion/venv/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:446: UserWarning: Checkpoint directory .torch_checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/dicarlo_d/Documents/Code/TurboSuperResultion/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1294: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(monitor='val/loss/tot')\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val/loss/tot\",\n",
    "    dirpath=\".torch_checkpoints\",\n",
    "    filename=\"Turb2D-%s-{epoch:02d}-{val_loss:.2f}\" % (hparams['name']),\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(gpus=0,\n",
    "                  max_epochs=5000, \n",
    "                  log_every_n_steps=20,\n",
    "                  check_val_every_n_epoch=20, \n",
    "                  callbacks=[early_stop_callback,\n",
    "                             checkpoint_callback])\n",
    "\n",
    "from turboflow.models.phyrff_hard import plDivFreeRFFNet\n",
    "model = plDivFreeRFFNet(**vars(Namespace(**hparams)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "521151f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 16\n",
      "65536 256\n",
      "tensor([0.0000, 0.0627, 0.1255, 0.1882, 0.2510, 0.3137, 0.3765, 0.4392, 0.5020,\n",
      "        0.5647, 0.6275, 0.6902, 0.7529, 0.8157, 0.8784, 0.9412])\n",
      "tensor([0.0000, 0.0039, 0.0078, 0.0118, 0.0157, 0.0196, 0.0235, 0.0275, 0.0314,\n",
      "        0.0353, 0.0392, 0.0431, 0.0471, 0.0510, 0.0549, 0.0588, 0.0627, 0.0667,\n",
      "        0.0706, 0.0745, 0.0784, 0.0824, 0.0863, 0.0902, 0.0941, 0.0980, 0.1020,\n",
      "        0.1059, 0.1098, 0.1137, 0.1176, 0.1216, 0.1255, 0.1294, 0.1333, 0.1373,\n",
      "        0.1412, 0.1451, 0.1490, 0.1529, 0.1569, 0.1608, 0.1647, 0.1686, 0.1725,\n",
      "        0.1765, 0.1804, 0.1843, 0.1882, 0.1922, 0.1961, 0.2000, 0.2039, 0.2078,\n",
      "        0.2118, 0.2157, 0.2196, 0.2235, 0.2275, 0.2314, 0.2353, 0.2392, 0.2431,\n",
      "        0.2471, 0.2510, 0.2549, 0.2588, 0.2627, 0.2667, 0.2706, 0.2745, 0.2784,\n",
      "        0.2824, 0.2863, 0.2902, 0.2941, 0.2980, 0.3020, 0.3059, 0.3098, 0.3137,\n",
      "        0.3176, 0.3216, 0.3255, 0.3294, 0.3333, 0.3373, 0.3412, 0.3451, 0.3490,\n",
      "        0.3529, 0.3569, 0.3608, 0.3647, 0.3686, 0.3725, 0.3765, 0.3804, 0.3843,\n",
      "        0.3882, 0.3922, 0.3961, 0.4000, 0.4039, 0.4078, 0.4118, 0.4157, 0.4196,\n",
      "        0.4235, 0.4275, 0.4314, 0.4353, 0.4392, 0.4431, 0.4471, 0.4510, 0.4549,\n",
      "        0.4588, 0.4627, 0.4667, 0.4706, 0.4745, 0.4784, 0.4824, 0.4863, 0.4902,\n",
      "        0.4941, 0.4980, 0.5020, 0.5059, 0.5098, 0.5137, 0.5176, 0.5216, 0.5255,\n",
      "        0.5294, 0.5333, 0.5373, 0.5412, 0.5451, 0.5490, 0.5529, 0.5569, 0.5608,\n",
      "        0.5647, 0.5686, 0.5725, 0.5765, 0.5804, 0.5843, 0.5882, 0.5922, 0.5961,\n",
      "        0.6000, 0.6039, 0.6078, 0.6118, 0.6157, 0.6196, 0.6235, 0.6275, 0.6314,\n",
      "        0.6353, 0.6392, 0.6431, 0.6471, 0.6510, 0.6549, 0.6588, 0.6627, 0.6667,\n",
      "        0.6706, 0.6745, 0.6784, 0.6824, 0.6863, 0.6902, 0.6941, 0.6980, 0.7020,\n",
      "        0.7059, 0.7098, 0.7137, 0.7176, 0.7216, 0.7255, 0.7294, 0.7333, 0.7373,\n",
      "        0.7412, 0.7451, 0.7490, 0.7529, 0.7569, 0.7608, 0.7647, 0.7686, 0.7725,\n",
      "        0.7765, 0.7804, 0.7843, 0.7882, 0.7922, 0.7961, 0.8000, 0.8039, 0.8078,\n",
      "        0.8118, 0.8157, 0.8196, 0.8235, 0.8275, 0.8314, 0.8353, 0.8392, 0.8431,\n",
      "        0.8471, 0.8510, 0.8549, 0.8588, 0.8627, 0.8667, 0.8706, 0.8745, 0.8784,\n",
      "        0.8824, 0.8863, 0.8902, 0.8941, 0.8980, 0.9020, 0.9059, 0.9098, 0.9137,\n",
      "        0.9176, 0.9216, 0.9255, 0.9294, 0.9333, 0.9373, 0.9412, 0.9451, 0.9490,\n",
      "        0.9529, 0.9569, 0.9608, 0.9647, 0.9686, 0.9725, 0.9765, 0.9804, 0.9843,\n",
      "        0.9882, 0.9922, 0.9961, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "X_lr, y_lr = dm.val_dataset[:]\n",
    "img_shape_lr = dm.val_dataset.img_shape[:2]\n",
    "shape_lr = dm.val_dataset.img_shape\n",
    "L = shape_lr[0]\n",
    "N_lr = X_lr.shape[0]\n",
    "print(N_lr, L)\n",
    "\n",
    "X_hr, y_hr = dm.test_dataset[:]\n",
    "img_shape_hr = dm.test_dataset.img_shape[:2]\n",
    "shape_hr = dm.test_dataset.img_shape\n",
    "H = shape_hr[0]\n",
    "N_hr = X_hr.shape[0]\n",
    "print(N_hr, H)\n",
    "\n",
    "print(X_lr.reshape(*shape_lr)[:,0,0])\n",
    "print(X_hr.reshape(*shape_hr)[:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e0255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from typing import List, Tuple\n",
    "Tensor = torch.Tensor\n",
    "FloatTensor = torch.FloatTensor\n",
    "import copy\n",
    "\n",
    "def _del_nested_attr(obj: nn.Module, names: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    Deletes the attribute specified by the given list of names.\n",
    "    For example, to delete the attribute obj.conv.weight,\n",
    "    use _del_nested_attr(obj, ['conv', 'weight'])\n",
    "    \"\"\"\n",
    "    if len(names) == 1:\n",
    "        delattr(obj, names[0])\n",
    "    else:\n",
    "        _del_nested_attr(getattr(obj, names[0]), names[1:])\n",
    "\n",
    "def extract_weights(mod: nn.Module) -> Tuple[Tuple[Tensor, ...], List[str]]:\n",
    "    \"\"\"\n",
    "    This function removes all the Parameters from the model and\n",
    "    return them as a tuple as well as their original attribute names.\n",
    "    The weights must be re-loaded with `load_weights` before the model\n",
    "    can be used again.\n",
    "    Note that this function modifies the model in place and after this\n",
    "    call, mod.parameters() will be empty.\n",
    "    \"\"\"\n",
    "    orig_params = tuple(mod.parameters())\n",
    "    # Remove all the parameters in the model\n",
    "    names = []\n",
    "    for name, p in list(mod.named_parameters()):\n",
    "        _del_nested_attr(mod, name.split(\".\"))\n",
    "        names.append(name)\n",
    "\n",
    "    '''\n",
    "    Make params regular Tensors instead of nn.Parameter\n",
    "    '''\n",
    "    params = tuple(p.detach().requires_grad_() for p in orig_params)\n",
    "    return params, names\n",
    "\n",
    "def _set_nested_attr(obj: nn.Module, names: List[str], value: Tensor) -> None:\n",
    "    \"\"\"\n",
    "    Set the attribute specified by the given list of names to value.\n",
    "    For example, to set the attribute obj.conv.weight,\n",
    "    use _del_nested_attr(obj, ['conv', 'weight'], value)\n",
    "    \"\"\"\n",
    "    if len(names) == 1:\n",
    "        setattr(obj, names[0], value)\n",
    "    else:\n",
    "        _set_nested_attr(getattr(obj, names[0]), names[1:], value)\n",
    "\n",
    "def load_weights(mod: nn.Module, names: List[str], params: Tuple[Tensor, ...]) -> None:\n",
    "    \"\"\"\n",
    "    Reload a set of weights so that `mod` can be used again to perform a forward pass.\n",
    "    Note that the `params` are regular Tensors (that can have history) and so are left\n",
    "    as Tensors. This means that mod.parameters() will still be empty after this call.\n",
    "    \"\"\"\n",
    "    for name, p in zip(names, params):\n",
    "        _set_nested_attr(mod, name.split(\".\"), p)\n",
    "\n",
    "def compute_jacobian(model, x):\n",
    "    '''\n",
    "\n",
    "    @param model: model with vector output (not scalar output!) the parameters of which we want to compute the Jacobian for\n",
    "    @param x: input since any gradients requires some input\n",
    "    @return: either store jac directly in parameters or store them differently\n",
    "\n",
    "    we'll be working on a copy of the model because we don't want to interfere with the optimizers and other functionality\n",
    "    '''\n",
    "\n",
    "    jac_model = copy.deepcopy(model) # because we're messing around with parameters (deleting, reinstating etc)\n",
    "    all_params, all_names = extract_weights(jac_model) # \"deparameterize weights\"\n",
    "    load_weights(jac_model, all_names, all_params) # reinstate all weights as plain tensors\n",
    "\n",
    "    def param_as_input_func(model, x, param):\n",
    "        load_weights(model, [name], [param]) # name is from the outer scope\n",
    "        out = model(x)\n",
    "        return out\n",
    "\n",
    "    for i, (name, param) in enumerate(zip(all_names, all_params)):\n",
    "        print(name, param.shape)\n",
    "        jac = torch.autograd.functional.jacobian(\n",
    "            lambda param: param_as_input_func(jac_model, x, param), param)\n",
    "        yield (name, param, jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d16dd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = 200\n",
    "N = X_lr.shape[0]\n",
    "inds = torch.randint(N,size=(1,I)).squeeze()\n",
    "\n",
    "X_mb_lr = X_lr[inds,:]\n",
    "X_mb_lr.requires_grad_(True)\n",
    "\n",
    "J1 = []\n",
    "for n, p, j in compute_jacobian(model, X_mb_lr):\n",
    "    J1.append(j[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b1c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "D1 = N\n",
    "D2 = N\n",
    "J2 = J1\n",
    "\n",
    "def compute_ntk(J1, D1, J2, D2):\n",
    "    Ker = torch.zeros([D1, D2])\n",
    "    for k in range(len(J1)):\n",
    "        j1 = J1[k].flatten(1)\n",
    "        j2 = J2[k].flatten(1)\n",
    "        K = torch.matmul(j1, j2.T)\n",
    "        Ker = Ker + K\n",
    "    return Ker\n",
    "\n",
    "K = compute_ntk(J1, D1, J2, D2)\n",
    "print(K.shape)\n",
    "\n",
    "c = torch.mean(torch.diag(K))\n",
    "\n",
    "lam_K = torch.real(torch.linalg.eigvals(K))\n",
    "lam_K = torch.sort(lam_K, descending=True)[0]\n",
    "\n",
    "plt.plot(torch.log(lam_K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d261e02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, dm)\n",
    "trainer.test(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f933f481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
