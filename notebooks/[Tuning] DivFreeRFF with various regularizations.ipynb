{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6328122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8824f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "046de65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import torch\n",
    "from pytorch_lightning.trainer import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from turboflow.dataloaders import TurboFlowDataModule\n",
    "from turboflow.evaluation import compute_all_metrics\n",
    "\n",
    "from turboflow.utils import phy_utils as phy\n",
    "from turboflow.utils import torch_utils as tch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc8bb501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed20650",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/dicarlo_d/Documents/Code/TurboSuperResultion/.cache/Turb2D.hdf5'\n",
    "dm = TurboFlowDataModule(dataset='Turb2D', \n",
    "                         data_dir=data_dir,\n",
    "                         batch_size=100000,\n",
    "                         time_idx=33,\n",
    "                         train_downsampling=4,\n",
    "                         val_downsampling=4,\n",
    "                         test_downsampling=1,\n",
    "                         num_workers=1)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ab9c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'name':'MLPvanilla',\n",
    "    'mlp_layers_num': 3, \n",
    "    'mlp_layers_dim': 256, \n",
    "    'mlp_last_actfn': 'tanh',\n",
    "    'do_rff': False, \n",
    "    'rff_num': 256, \n",
    "    'rff_scale': 10,\n",
    "    'do_divfree': False,\n",
    "    'lam_pde': 0, \n",
    "    'lam_div': 0,\n",
    "    'lam_reg': 0,\n",
    "    'lam_sfn': 0,\n",
    "    'lam_spec': 0,\n",
    "    'sfn_min_x': 0.00784314,\n",
    "    'sfn_num_centers': 50,\n",
    "    'sfn_num_increments':3,\n",
    "    'sfn_patch_dim': 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdef8b72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/dicarlo_d/Documents/Code/TurboSuperResultion/venv/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2021-10-27 22:03:09.678278: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-27 22:03:09.678308: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | mlp  | MLP  | 132 K \n",
      "------------------------------\n",
      "132 K     Trainable params\n",
      "0         Non-trainable params\n",
      "132 K     Total params\n",
      "0.531     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ab5423a4bf4510852d372a3963695c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dicarlo_d/Documents/Code/TurboSuperResultion/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 42\n",
      "/home/dicarlo_d/Documents/Code/TurboSuperResultion/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b23e39efb94fe68f8452ca3500a3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561280ccbb6c4bc0b0a3313a36433790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173b023834e04d6bb8d051fd9438cade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dicarlo_d/Documents/Code/TurboSuperResultion/venv/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/dicarlo_d/Documents/Code/TurboSuperResultion/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b711131b794c0f993b069da36e5521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test/loss/div': 0.0,\n",
      " 'test/loss/pde': 0.0,\n",
      " 'test/loss/rec': 0.05553190037608147,\n",
      " 'test/loss/reg': 0.0,\n",
      " 'test/loss/sfn': 0.0,\n",
      " 'test/loss/spec': 0.0,\n",
      " 'test/metrics/angular_degree': 16.274120330810547,\n",
      " 'test/metrics/log_err_specturm': 32.5950927734375,\n",
      " 'test/metrics/reconstruction': 0.11106379330158234,\n",
      " 'test_loss': 0.05553190037608147}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.05553190037608147,\n",
       "  'test/loss/sfn': 0.0,\n",
       "  'test/loss/rec': 0.05553190037608147,\n",
       "  'test/loss/pde': 0.0,\n",
       "  'test/loss/div': 0.0,\n",
       "  'test/loss/reg': 0.0,\n",
       "  'test/loss/spec': 0.0,\n",
       "  'test/metrics/reconstruction': 0.11106379330158234,\n",
       "  'test/metrics/angular_degree': 16.274120330810547,\n",
       "  'test/metrics/log_err_specturm': 32.5950927734375}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(monitor='val_loss')\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=\".torch_checkpoints\",\n",
    "    filename=\"Turb2D-%s-{epoch:02d}-{val_loss:.2f}\" % (hparams['name']),\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(gpus=1,\n",
    "                  max_epochs=5000, \n",
    "                  log_every_n_steps=1,\n",
    "                  check_val_every_n_epoch=1, \n",
    "                  callbacks=[early_stop_callback,\n",
    "                             checkpoint_callback])\n",
    "\n",
    "from turboflow.models.phyrff_hard import plDivFreeRFFNet\n",
    "model = plDivFreeRFFNet(**vars(Namespace(**hparams)))\n",
    "\n",
    "trainer.fit(model, dm)\n",
    "trainer.test(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c34579",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = plDivFreeRFFNet.load_from_checkpoint(checkpoint_callback.best_model_path)\n",
    "trainer.test(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da145ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lr, y_lr = dm.val_dataset[:]\n",
    "img_shape_lr = dm.val_dataset.img_shape\n",
    "\n",
    "X_hr, y_hr = dm.test_dataset[:]\n",
    "img_shape_hr = dm.test_dataset.img_shape\n",
    "\n",
    "print(X_lr.shape, y_lr.shape)\n",
    "print(X_hr.shape, y_hr.shape)\n",
    "\n",
    "y_hat_lr, Py_hat_lr = model(X_lr)\n",
    "y_hat_hr, Py_hat_hr = model(X_hr)\n",
    "\n",
    "print(y_hat_lr.shape)\n",
    "print(y_hat_hr.shape)\n",
    "print(Py_hat_lr)\n",
    "print(Py_hat_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addd0d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_all_metrics(y_hat_lr, y_lr))\n",
    "print(compute_all_metrics(y_hat_hr, y_hr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6f60e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute spectrum\n",
    "spec_cat = phy.energy_spectrum(torch.randn(*img_shape_hr).permute(2,0,1))[0]\n",
    "spec_ns = phy.energy_spectrum(torch.randn(*img_shape_hr).permute(2,0,1))[0]\n",
    "spec_lr = phy.energy_spectrum(y_lr.view(*img_shape_lr).permute(2,0,1))[0]\n",
    "spec_hr = phy.energy_spectrum(y_hr.view(*img_shape_hr).permute(2,0,1))[0]\n",
    "\n",
    "spec_lr_pred = phy.energy_spectrum(y_hat_lr.view(*img_shape_lr).permute(2,0,1))[0]\n",
    "spec_hr_pred = phy.energy_spectrum(y_hat_hr.view(*img_shape_hr).permute(2,0,1))[0]\n",
    "\n",
    "plt.loglog(spec_ns)\n",
    "plt.loglog(spec_lr)\n",
    "plt.loglog(spec_hr)\n",
    "plt.loglog(spec_lr_pred.detach())\n",
    "plt.loglog(spec_hr_pred.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f705448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spec error\n",
    "spec_log_error_lr = torch.norm(torch.log(spec_lr_pred+1e-20) - torch.log(spec_lr+1e-20))**2\n",
    "spec_log_error_hr = torch.norm(torch.log(spec_hr_pred+1e-20) - torch.log(spec_hr+1e-20))**2\n",
    "\n",
    "print(spec_error_lr.item())\n",
    "print(spec_error_hr.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b426d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# angular error\n",
    "def ang_error(x, x_ref, avg=True):\n",
    "    assert x.shape == x_ref.shape\n",
    "    assert x.shape[1] == 2\n",
    "    N = x.shape[0]\n",
    "    \n",
    "    w1 = torch.cat([x, torch.ones(x.shape[0], 1)], dim=1)\n",
    "    w2 = torch.cat([x_ref, torch.ones(x_ref.shape[0], 1)], dim=1)\n",
    "    \n",
    "    err = torch.sum(w1 * w2, dim=1) / (torch.norm(w1, dim=1) * torch.norm(w2, dim=1))\n",
    "    assert err.sum() < N\n",
    "    err = torch.rad2deg(torch.acos(err))\n",
    "    if avg:\n",
    "        return err.mean()\n",
    "    return err\n",
    "    \n",
    "\n",
    "ang_err_lr = ang_error(y_lr, y_hat_lr, avg=True)\n",
    "ang_err_hr = ang_error(y_hr, y_hat_hr, avg=True)\n",
    "\n",
    "print(torch.max(ang_error(y_lr, y_hat_lr, avg=False)))\n",
    "print(torch.max(ang_error(y_hr, y_hat_hr, avg=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_lr_err = phy.energy_spectrum(((y_hat_lr-y_lr)**2).view(*img_shape_lr).permute(2,0,1))[0]\n",
    "spec_hr_err = phy.energy_spectrum(((y_hat_hr-y_hr)**2).view(*img_shape_hr).permute(2,0,1))[0]\n",
    "\n",
    "plt.loglog(spec_lr_err.detach())\n",
    "plt.loglog(spec_hr_err.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abfbd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat, Py_hat = model(X_lr)\n",
    "u, v = torch.split(y_hat,1,-1)\n",
    "du_xy = torch.autograd.grad(u, X_lr, torch.ones_like(u), create_graph=True)[0]       \n",
    "dv_xy = torch.autograd.grad(v, X_lr, torch.ones_like(v), create_graph=True)[0]\n",
    "# div_autograd = du_xy[...,0] + dv_xy[...,1]\n",
    "div_autograd = dv_xy[...,1]\n",
    "div_autograd = div_autograd.view(*img_shape_lr[:2])\n",
    "\n",
    "plt.imshow(div_autograd.detach())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "du_x = tch._my_field_grad(y_hat.view(*img_shape_lr)[:,:,0], 1)\n",
    "du_y = tch._my_field_grad(y_hat.view(*img_shape_lr)[:,:,1], 0)\n",
    "div_numerical = du_y\n",
    "    \n",
    "plt.imshow(div_numerical.detach())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow((div_numerical - div_autograd).detach())\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67538680",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat, Py_hat = model(X_hr)\n",
    "u, v = torch.split(y_hat,1,-1)\n",
    "du_xy = torch.autograd.grad(u, X_hr, torch.ones_like(u), create_graph=True)[0]       \n",
    "dv_xy = torch.autograd.grad(v, X_hr, torch.ones_like(v), create_graph=True)[0]\n",
    "# div_autograd = du_xy[...,0] + dv_xy[...,1]\n",
    "div_autograd = dv_xy[...,1]\n",
    "div_autograd = div_autograd.view(*img_shape_hr[:2])\n",
    "\n",
    "plt.imshow(div_autograd[2:-2,2:-2].detach())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "du_x = tch._my_field_grad(y_hat.view(*img_shape_hr)[:,:,0], 1)\n",
    "du_y = tch._my_field_grad(y_hat.view(*img_shape_hr)[:,:,1], 0)\n",
    "div_numerical = du_y\n",
    "    \n",
    "plt.imshow(div_numerical[2:-2,2:-2].detach())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow((div_numerical[2:-2,2:-2] - div_autograd[2:-2,2:-2]).detach())\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f883a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
